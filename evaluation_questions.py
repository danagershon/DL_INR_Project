import torch
import torch.nn as nn
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from utils import vec_to_img


def plot_confusion_matrix(true_labels, predicted_labels, class_names, set_name):
    """
    Plots and saves confusion matrix for given true and predicted labels 
    
    :param true_labels: dataset true labls
    :param predicted_labels: dataset predicted labels
    :param class_names: List of class names (e.g., ['0', '1', ..., '9'] for Fashion MNIST)
    :param set_name: Name of the dataset (e.g., 'Train', 'Validation', 'Test') for the plot title
    """
    cm = confusion_matrix(true_labels, predicted_labels)

    # Plot confusion matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.title(f'Confusion Matrix - {set_name} Set')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    
    # Save the plot to a file
    output_file = set_name.replace(" ", "_") + '_confusion_matrix.png'
    plt.savefig(output_file)
    plt.close()  # Close the figure to prevent it from displaying
    
    print(f"Confusion matrix for {set_name} set saved as {output_file}")


def plot_confusion_matrix_for_model(model, loader, class_names, set_name, device='cuda'):
    """
    Plots and saves confusion matrix for a given dataset.
    
    :param model: Trained model
    :param loader: DataLoader for dataset
    :param class_names: List of class names (e.g., ['0', '1', ..., '9'] for Fashion MNIST)
    :param set_name: Name of the dataset (e.g., 'Train', 'Validation', 'Test') for the plot title
    :param device: Device ('cuda' or 'cpu') to run inference
    """
    model.eval()
    true_labels = []
    predicted_labels = []
    
    with torch.no_grad():
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            predicted = torch.argmax(outputs, 1)
            true_labels.extend(labels.detach().cpu().numpy())
            predicted_labels.extend(predicted.detach().cpu().numpy())
    
    plot_confusion_matrix(true_labels, predicted_labels, class_names, set_name)


def plot_accuracies_after_attack(linf_bounds, accuracies):
    """
    Plot classification accuracy vs. L inf bounds.
    
    :param linf_bounds: List of L inf bounds (epsilon values)
    :param accuracies: List of corresponding classification accuracies
    """
    plt.figure(figsize=(8, 6))
    plt.plot(linf_bounds, accuracies, marker='o', linestyle='-', color='b')
    plt.xscale('log')  # Use a logarithmic scale for the x-axis since epsilon values vary exponentially
    plt.xlabel('L inf Bound (epsilon)')
    plt.ylabel('Classification Accuracy (%)')
    plt.title('Adversarial Attack: Accuracy vs. L inf Bound')
    plt.grid(True)

    output_file='attack_accuracy_plot.png'
    plt.savefig(output_file)
    plt.close()
    print(f"Plot saved to {output_file}")


def visualize_class_attack_results(clean_vectors, perturbations, labels, predictions, class_names, inr_model, selected_classes, num_samples=1, device='cuda'):
    """
    Visualize clean image, perturbation, and perturbed image for successful and failed attacks for specific classes.
    
    :param clean_vectors: Original vectors before attack
    :param perturbations: Perturbations generated by the attack
    :param labels: True labels for the samples
    :param predictions: Predictions made by the classifier
    :param class_names: List of class names
    :param inr_model: Pre-trained INR model to convert modulation vectors back to images
    :param selected_classes: Classes to visualize (list of 3 class indices)
    :param num_samples: Number of samples to visualize for successful and failed attacks (per class)
    :param device: Device ('cuda' or 'cpu') to run inference
    """
    fig, axs = plt.subplots(len(selected_classes), 6, figsize=(18, len(selected_classes) * 6))

    for class_idx, class_label in enumerate(selected_classes):
        success_count = 0
        fail_count = 0
        for i in range(len(labels)):
            if labels[i] == class_label:
                clean_vec = torch.tensor(clean_vectors[i]).to(device)
                perturbation = torch.tensor(perturbations[i]).to(device)
                perturbed_vec = clean_vec + perturbation
                
                # Successful attack: classifier predicted incorrectly after perturbation
                if predictions[i] != labels[i] and success_count < num_samples:
                    # Clean image
                    clean_img = vec_to_img(inr_model, clean_vec).detach().cpu().numpy()
                    axs[class_idx, 0].imshow(clean_img, cmap='gray')
                    axs[class_idx, 0].set_title(f'{class_names[class_label]} Clean Image (Success)')
                    
                    # Perturbation
                    perturb_img = perturbation.detach().cpu().numpy()
                    axs[class_idx, 1].imshow(perturb_img, cmap='gray')
                    axs[class_idx, 1].set_title('Perturbation (Success)')

                    # Perturbed image
                    perturbed_img = vec_to_img(inr_model, perturbed_vec).detach().cpu().numpy()
                    axs[class_idx, 2].imshow(perturbed_img, cmap='gray')
                    axs[class_idx, 2].set_title('Perturbed Image (Success)')
                    
                    success_count += 1
                
                # Failed attack: classifier predicted correctly after perturbation
                if predictions[i] == labels[i] and fail_count < num_samples:
                    # Clean image
                    clean_img = vec_to_img(inr_model, clean_vec).detach().cpu().numpy()
                    axs[class_idx, 3].imshow(clean_img, cmap='gray')
                    axs[class_idx, 3].set_title(f'{class_names[class_label]} Clean Image (Fail)')
                    
                    # Perturbation
                    perturb_img = perturbation.detach().cpu().numpy()
                    axs[class_idx, 4].imshow(perturb_img, cmap='gray')
                    axs[class_idx, 4].set_title('Perturbation (Fail)')

                    # Perturbed image
                    perturbed_img = vec_to_img(inr_model, perturbed_vec).detach().cpu().numpy()
                    axs[class_idx, 5].imshow(perturbed_img, cmap='gray')
                    axs[class_idx, 5].set_title('Perturbed Image (Fail)')
                    
                    fail_count += 1

                # Stop if we've collected enough samples for this class
                if success_count >= num_samples and fail_count >= num_samples:
                    break

    plt.tight_layout()
    output_file='class_attack_visualization.png'
    plt.savefig(output_file)
    plt.close()
    print(f"Visualization saved to {output_file}")
